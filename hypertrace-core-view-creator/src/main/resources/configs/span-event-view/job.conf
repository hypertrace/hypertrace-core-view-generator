mainClass = org.hypertrace.core.viewcreator.pinot.PinotTableCreationTool

view.name = spanEventView
view.output.schema.class = org.hypertrace.core.viewgenerator.api.SpanEventView
view.output.schema.url = "host:port/myView"

kafka.brokerAddress = "bootstrap:9092"
kafka.topicName = span-event-view
kafka.partitions = 1
kafka.replicationFactor = 1

pinot.controllerHost = pinot-controller
pinot.controllerPort = 9000
pinot.timeColumn = start_time_millis
pinot.timeUnit = MILLISECONDS
pinot.dimensionColumns = [tenant_id, span_id, span_kind, parent_span_id, trace_id, tags__KEYS, tags__VALUES, start_time_millis, end_time_millis, duration_millis, service_name, event_name, display_span_name, status_code]
pinot.columnsMaxLength = {}
pinot.metricColumns = []
pinot.invertedIndexColumns = [tags__KEYS, tags__VALUES]
pinot.rangeIndexColumns = [start_time_millis]
pinot.bloomFilterColumns = []
pinot.noDictionaryColumns = []
pinot.tableName = spanEventView
pinot.loadMode = MMAP
pinot.numReplicas = 1
pinot.retentionTimeValue = 5
pinot.retentionTimeUnit = DAYS
pinot.brokerTenant = defaultBroker
pinot.serverTenant = defaultServer
pinot.segmentAssignmentStrategy = BalanceNumSegmentAssignmentStrategy

pinot.streamConfigs =
  {
    streamType: kafka,
    stream.kafka.consumer.type: LowLevel,
    stream.kafka.topic.name: span-event-view,
    stream.kafka.consumer.factory.class.name: "org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory",
    stream.kafka.decoder.class.name: "org.apache.pinot.plugin.inputformat.avro.confluent.KafkaConfluentSchemaRegistryAvroMessageDecoder",
    stream.kafka.decoder.prop.schema.registry.rest.url: "http://schema-registry-service:8081",
    stream.kafka.hlc.zk.connect.string: "zookeeper:2181",
    stream.kafka.zk.broker.url: "zookeeper:2181",
    stream.kafka.broker.list: "bootstrap:9092",
    realtime.segment.flush.threshold.time: 3600000,
    realtime.segment.flush.threshold.size: 500000,
    stream.kafka.consumer.prop.auto.offset.reset: largest
  }
